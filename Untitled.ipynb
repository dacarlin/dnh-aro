{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *De novo* design of an allyl hydratase\n",
    "\n",
    "In this repo, we're designing for a large, aromatic substrate, 2-allylphenol. If we can show that we can get activity on that substrate (and if it's soluble), we'll move on to ethylene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file prep \n",
    "\n",
    "We prepped our scaffold set, wrote constraint file, and generated ligand params file. \n",
    "\n",
    "## Match the theozyme into our scaffold set \n",
    "\n",
    "### RosettaMatch run on scaffold set (207 proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a list of input structures \n",
    "from glob import glob \n",
    "runs = [ '-s {} -match:scaffold_active_site_residues {}'.format( s, s.replace( 'pdb', 'pos' ) ) for s in glob( 'scaffold_set/*pdb' ) ] \n",
    "with open( 'match/list', 'w' ) as fn:\n",
    "    fn.write( '\\n'.join( runs ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 runs\n",
      "Submitted batch job 694932\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "runs=$( wc -l match/list | cut -d\" \" -f1 )\n",
    "echo $runs runs\n",
    "\n",
    "cd match && sbatch --array=1-$runs sub.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "        694932_203        gc dnh_matc   carlin  R       4:51      1 c0-2.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_204        gc dnh_matc   carlin  R       4:51      1 c0-2.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_205        gc dnh_matc   carlin  R       4:51      1 c0-2.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_206        gc dnh_matc   carlin  R       4:51      1 c0-2.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_102        gc dnh_matc   carlin  R       4:52      1 c0-0.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_103        gc dnh_matc   carlin  R       4:52      1 c0-16.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_104        gc dnh_matc   carlin  R       4:52      1 c0-16.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_105        gc dnh_matc   carlin  R       4:52      1 c0-16.hpc.genomecenter.ucdavis.edu\r\n",
      "        694932_106        gc dnh_matc   carlin  R       4:52      1 c0-16.hpc.genomecenter.ucdavis.edu\r\n"
     ]
    }
   ],
   "source": [
    "! squeue -u carlin | head "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting our matches to the enzyme design protocol \n",
    "\n",
    "Now that we have matched the active site residues and the ligand into various positions in the protein backbones of our scaffold set, we'll use an enzyme design protocol to optimize the ligand placement and shape complementarity with the protein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use nstruct 10 here since each job is only taking a few minutes, it's OK if they run overnight \n",
    "\n",
    "from glob import glob\n",
    "nstruct = 5 \n",
    "\n",
    "runs = [ '-s ../{} -suffix _{}'.format( i, j ) for j in range( nstruct ) for i in glob( 'match/out/*pdb' ) ]\n",
    "with open( 'enzdes/list', 'w' ) as fn:\n",
    "    fn.write( '\\n'.join( runs ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wc -l enzdes/list\n",
    "! head enzdes/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# let's start with doing 100 and making sure everything is OK \n",
    "# cd enzdes && sbatch --array=1-100 sub.sh \n",
    "\n",
    "# now the rest \n",
    "# cd enzdes && sbatch --array=101-$( wc -l list | cut -d\" \" -f1 ) sub.sh \n",
    "\n",
    "# now the real\n",
    "# cd enzdes && sbatch --array=1-$( wc -l list | cut -d\" \" -f1 ) sub.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! squeue -u carlin | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "### Filter the RosettaScripts enzyme design output \n",
    "\n",
    "Let's start by looking at histograms of the `total_score` of each of the catalytic residues. Because we're looking at a big ligand, let's also check out the interface energy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download scorefiles from cluster \n",
    "! rsync -avz $ep:/share/work/alex/dnh_aro/enzdes/out/*sc designs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from glob import glob \n",
    "\n",
    "dfs = [ pandas.read_csv( i, sep='\\s+' ) for i in glob( 'designs/*sc' ) ]\n",
    "df = pandas.concat( dfs ).dropna()\n",
    "df['scaffold'] = df.description.str.split( '_' ).str.get( 4 ) \n",
    "df['match'] = df.description.str.split( '_11' ).str[0]\n",
    "\n",
    "print len( df ), 'enzdes out'\n",
    "print len( df.scaffold.unique() ), 'scaffolds'\n",
    "print len( df.match.unique() ), 'unique matches'\n",
    "\n",
    "# sf = pandas.read_csv( 'enzdes/out/score.sc', sep='\\s+' )\n",
    "# sf.index = sf.description\n",
    "# sf['scaffold'] = sf.index.str.split( '_' ).str[4]\n",
    "# sf['match'] = sf.index.str.split( '_11' ).str[0]\n",
    "# sf.sample( 3 )\n",
    "\n",
    "# print len( sf ), 'enzdes out'\n",
    "# print len( sf.scaffold.unique() ), 'scaffolds'\n",
    "# print len( sf.match.unique() ), 'unique matches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get lowest 1 of each nstruct \n",
    "\n",
    "def lowest( df ):\n",
    "    return df.sort( 'total_score' ).head( 1 )\n",
    "\n",
    "grouped = df.groupby( 'match' ).apply( lowest )\n",
    "print len( grouped ), 'lowest from nstruct groups (should equal number of matches)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = grouped[ \n",
    "    ( grouped.all_cst < 1 ) & \n",
    "    ( grouped.SR_1_total_score < 0 ) & \n",
    "    ( grouped.SR_2_total_score < 0 ) & \n",
    "    ( grouped.SR_3_total_score < 0 ) & \n",
    "    ( grouped.SR_3_dsasa_1_2 > 0.9 ) \n",
    "]\n",
    "\n",
    "print len( filtered ), 'structures meet critera'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms of all the columns in the scorefile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sf.hist( linewidth=0, color='k', figsize=( 12, 120 ), bins=50, layout=(41,1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per-scaffold histograms! (Why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sf.total_score.hist(by=df.scaffold, figsize=(21,21), color='k', linewidth=0 )\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered.sample( 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this when working on the cluster \n",
    "\n",
    "# from subprocess import call \n",
    "\n",
    "# tar_list = [ 'dnh_aro/enzdes/out/{}.pdb'.format( i ) for i in filtered.description ]\n",
    "# cmd = [ 'tar', '--create', '--verbose', '--file', 'filtered.tar' ] + tar_list \n",
    "# #call( cmd )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this when working on local machine \n",
    "\n",
    "pull_list = [ 'dnh_aro/enzdes/out/{}.pdb'.format( i ) for i in filtered.description ]\n",
    "with open( 'results/pull_list', 'w' ) as fn:\n",
    "    fn.write( '\\n'.join( pull_list ) )\n",
    "\n",
    "#! head pull_list   \n",
    "! rsync -avz --files-from=pull_list $ep:. results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Manual curation of structures \n",
    "\n",
    "Now that we have run Rosetta simulations and picked a set of design critera to fiter by, it's time for manual curation of the structures. We'll download the 50 or so that look the best, and pick some designs to order. \n",
    "\n",
    "One thing that I really like to see when looking at a design is the mutations that were made when compared to the wild type enzyme. Let's diff the designs against their wild types (only those in the filtered list though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, let's try to automate the curation step. Let's write a function that\n",
    "\n",
    "+ takes a design PDB file name in enzdes/out\n",
    "\n",
    "and makes a nice PyMOL session with \n",
    "\n",
    "+ the wild type loaded and overlayed \n",
    "+ mutations colored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio.PDB.Polypeptide import PPBuilder\n",
    "from Bio.PDB import PDBParser\n",
    "import string \n",
    "\n",
    "def return_seq( pdb ):\n",
    "    '''\n",
    "    Utility function to get a FASTA-like sequence from a PDB file \n",
    "    '''\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure( pdb[:-4], pdb )\n",
    "    ppb = PPBuilder() # lol why don't these have PDBParser( 'XZY1.pdb' )-style constructors? \n",
    "    for pp in ppb.build_peptides( structure ):\n",
    "        sequence = pp.get_sequence()\n",
    "        return sequence \n",
    "\n",
    "def my_map( design ):\n",
    "    '''\n",
    "    Utility function that will fetch the design and WT PDBs from disk, diff them, \n",
    "    as well as generate a nice PyMOL script for looking at them later \n",
    "    '''\n",
    "    wild_type_pdb = 'scaffold_set/{}_11.pdb'.format( design.split( '_' )[4] )\n",
    "    design_pdb = 'results/dnh_aro/enzdes/out/{}.pdb'.format( design )\n",
    "    #print os.path.isfile( wild_type_pdb ), wild_type_pdb, os.path.isfile( design_pdb ), design_pdb\n",
    "    wt_seq = return_seq( wild_type_pdb )\n",
    "    des_seq = return_seq( design_pdb )\n",
    "    diff = [ '{}{}{}'.format( i, n+1, j ) for n, (i, j) in enumerate( zip( wt_seq, des_seq ) ) if i != j ]\n",
    "    string_rep = '+'.join( diff )\n",
    "    \n",
    "    with open( 'results/{}.pml'.format( design ), 'w' ) as fn:\n",
    "        filestring = \"\"\"\n",
    "load ~/Documents/dnh-aro/{0}, wt; load ~/Documents/dnh-aro/{1}, design;  \n",
    "clean; orient resn LG1; stored.design_ca = []; stored.wt_ca = []; \n",
    "iterate obj design and name ca, stored.design_ca.append( resn ); \n",
    "iterate obj wt and name ca, stored.wt_ca.append( resn ) ; \n",
    "select muts, resi {2} and obj design; util.cbaw muts; util.cnc; \n",
    "        \"\"\".format( \n",
    "            wild_type_pdb, \n",
    "            design_pdb, \n",
    "            string_rep.translate( None, string.letters )\n",
    "        )\n",
    "        fn.write( filestring )\n",
    "    \n",
    "    # print out some nice markdown we can use in a the next cell lol \n",
    "#     print '### {}\\n'.format( design ) \n",
    "#     print '**Scaffold**: {} \\n\\n **Mutations**: {}\\n'.format( design.split( '_' )[4], string_rep )\n",
    "#     match_series = filtered.loc[ design.split( '_11' )[0] ]\n",
    "#     print '  + total_score: {}\\n'.format( match_series.total_score.values[0] )\n",
    "#     print '  + Tyrosine score: {}\\n'.format( match_series.SR_1_total_score.values[0] )\n",
    "#     print '  + Glu/Asp score: {}\\n'.format( match_series.SR_2_total_score.values[0] )\n",
    "#     print '  + Ligand score: {}\\n'.format( match_series.SR_3_total_score.values[0] )\n",
    "#     print '**Notes**: \\n'\n",
    "#     print '---'\n",
    "#     print ''\n",
    "    \n",
    "    return string_rep\n",
    "    \n",
    "filtered['mutations'] = filtered.description.map( my_map )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new notebook with design data that can be used to keep notes \n",
    "\n",
    "Use this if you want to make a new notebook with seperate cells for each design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nbformat import current as nbf\n",
    "\n",
    "nb = nbf.new_notebook()\n",
    "\n",
    "header_cell = nbf.new_text_cell( 'markdown', '# Design notes\\n\\n {} designs'.format( len( filtered ) ) )\n",
    "\n",
    "cells = [ header_cell ]\n",
    "\n",
    "for i, series in filtered.iterrows():\n",
    "    \n",
    "    info = [ \n",
    "        '### {}'.format( series.description ), \n",
    "        '**Scaffold**: {}\\n'.format( series.scaffold ), \n",
    "        '**Mutations**: {}\\n'.format( series.mutations ),\n",
    "        '  + `total_score`: {}'.format( series.total_score ),\n",
    "        '  + Tyrosine `total_score`: {}'.format( series.SR_1_total_score ),\n",
    "        '  + Glu/Asp `total_score`: {}'.format( series.SR_2_total_score ),\n",
    "        '  + Ligand `total_score`: {}\\n'.format( series.SR_1_total_score ),\n",
    "        '**Notes**: \\n\\n --- \\n' \n",
    "    ]\n",
    "    \n",
    "    cell = nbf.new_text_cell( 'markdown', '\\n'.join( info ) )\n",
    "    cells.append( cell ) \n",
    "\n",
    "nb['worksheets'].append(nbf.new_worksheet(cells=cells))\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "with open( 'results/results_{}.ipynb'.format( datetime.now() ), 'w') as f:\n",
    "    nbf.write(nb, f, 'ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
