{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *De novo* design of an allyl hydratase\n",
    "\n",
    "In this repo, we're designing for a large, aromatic substrate, 2-allylphenol. If we can show that we can get activity on that substrate (and if it's soluble), we'll move on to ethylene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file prep \n",
    "\n",
    "We prepped our scaffold set, wrote constraint file, and generated ligand params file. \n",
    "\n",
    "## Match the theozyme into our scaffold set \n",
    "\n",
    "### Prep input files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a list of input structures \n",
    "from glob import glob \n",
    "runs = [ '-s {} -match:scaffold_active_site_residues {}'.format( s[6:], s[6:].replace( 'pdb', 'pos' ) ) for s in glob( 'match/scaffold_set/*pdb' ) ] \n",
    "with open( 'match/list', 'w' ) as fn:\n",
    "    fn.write( '\\n'.join( runs ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RosettaMatch run on scaffold set (207 proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "#cat out_of_mem_list > match/list\n",
    "runs=$( wc -l match/list | cut -d\" \" -f1 )\n",
    "echo $runs runs\n",
    "\n",
    "cd match && sbatch --array=1-$runs sub.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match results \n",
    "\n",
    "Using the classic match algorithm for both catalytic residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the ones that still fail at 16 GB\n",
    "# ! grep -i memory match/logs/slurm-741482_{1..40}.err | cut -d: -f1 | sort | uniq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the jobs crash with only 8 GB of RAM, so we will collect those and run them again, bumping up the RAM per core to 16 GB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#! ls -1 match/UM*pdb | wc -l #number of matches \n",
    "# ! squeue -u carlin | grep match | wc -l \n",
    "#! grep CANCELLED match/logs/*740932* | grep . | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! grep -i memory match/logs/slurm-740932_{1..206}.err | cut -d: -f1 | sort | uniq > out_of_mem \n",
    "#! ( for i in \"$( cat out_of_mem )\"; do head -2 ${i/err/out} | tail -n 1 | cut -d@ -f2 | cut -c 7-; done ) > out_of_mem_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit matches to enzyme design \n",
    "\n",
    "Now that we have matched the active site residues and the ligand into various positions in the protein backbones of our scaffold set, we'll use an enzyme design protocol to optimize the ligand placement and shape complementarity with the protein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "nstruct = 5 \n",
    "\n",
    "runs = [ \n",
    "    '-s ../{} -suffix _{:04d}\\n'.format( i, j ) \n",
    "    for j in range( nstruct ) \n",
    "    for i in glob( 'match/UM*pdb' ) \n",
    "]\n",
    "\n",
    "with open( 'enzdes/list', 'w' ) as fn:\n",
    "    fn.write( ''.join( runs ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wc -l enzdes/list\n",
    "! tail enzdes/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#rm enzdes/logs/* \n",
    "cd enzdes && echo sbatch -p gc128 --array=1-$( wc -l list | cut -d\" \" -f1 ) sub.sh \n",
    "\n",
    "# now the rest \n",
    "# cd enzdes && sbatch --array=101-$( wc -l list | cut -d\" \" -f1 ) sub.sh \n",
    "\n",
    "# now the real\n",
    "# cd enzdes && sbatch --array=1-$( wc -l list | cut -d\" \" -f1 ) sub.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! squeue -u carlin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls enzdes/out/*sc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "### Filter the RosettaScripts enzyme design output \n",
    "\n",
    "Let's start by looking at histograms of the `total_score` of each of the catalytic residues. Because we're looking at a big ligand, let's also check out the interface energy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receiving file list ... done\n",
      "\n",
      "sent 20 bytes  received 208 bytes  152.00 bytes/sec\n",
      "total size is 34019950  speedup is 149210.31\n"
     ]
    }
   ],
   "source": [
    "# download scorefiles from cluster \n",
    "! rsync -avz $ep:/share/work/alex/dnh-aro/enzdes/try_1_out/*sc results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45184 enzdes out\n",
      "175 scaffolds\n",
      "10637 unique matches\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from glob import glob \n",
    "\n",
    "dfs = [ pandas.read_csv( i, sep='\\s+' ) for i in glob( 'results/*sc' ) ]\n",
    "df = pandas.concat( dfs ).dropna()\n",
    "df['scaffold'] = df.description.str.split( '_' ).str.get( 4 ) \n",
    "df['match'] = df.description.str.split( '_11' ).str[0]\n",
    "\n",
    "print len( df ), 'enzdes out'\n",
    "print len( df.scaffold.unique() ), 'scaffolds'\n",
    "print len( df.match.unique() ), 'unique matches'\n",
    "\n",
    "# sf = pandas.read_csv( 'enzdes/out/score.sc', sep='\\s+' )\n",
    "# sf.index = sf.description\n",
    "# sf['scaffold'] = sf.index.str.split( '_' ).str[4]\n",
    "# sf['match'] = sf.index.str.split( '_11' ).str[0]\n",
    "# sf.sample( 3 )\n",
    "\n",
    "# print len( sf ), 'enzdes out'\n",
    "# print len( sf.scaffold.unique() ), 'scaffolds'\n",
    "# print len( sf.match.unique() ), 'unique matches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10637 lowest from nstruct groups (should equal number of matches)\n"
     ]
    }
   ],
   "source": [
    "# get lowest 1 of each nstruct \n",
    "\n",
    "def lowest( df ):\n",
    "    return df.sort_values( by='total_score' ).head( 1 )\n",
    "\n",
    "low1 = df.groupby( 'match' ).apply( lowest )\n",
    "print len( low1 ), 'lowest from nstruct groups (should equal number of matches)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 structures filtered of 10637 lowest energy\n"
     ]
    }
   ],
   "source": [
    "filtered = grouped[ \n",
    "    ( low1.all_cst < 1 ) & \n",
    "    ( low1.SR_1_total_score < -1 ) & \n",
    "    ( low1.SR_2_total_score < -1 ) & \n",
    "    ( low1.SR_3_total_score < -1 ) & \n",
    "    ( low1.SR_3_dsasa_1_2 > 0.90 ) \n",
    "]\n",
    "\n",
    "print len( filtered ), 'structures filtered of', len( low1 ), 'lowest energy'\n",
    "filtered.to_csv( 'results/filtered.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sf.hist( linewidth=0, color='k', figsize=( 12, 120 ), bins=50, layout=(41,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sf.total_score.hist(by=df.scaffold, figsize=(21,21), color='k', linewidth=0 )\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this when working on the cluster \n",
    "\n",
    "# from subprocess import call \n",
    "\n",
    "# tar_list = [ 'dnh_aro/enzdes/out/{}.pdb'.format( i ) for i in filtered.description ]\n",
    "# cmd = [ 'tar', '--create', '--verbose', '--file', 'filtered.tar' ] + tar_list \n",
    "# #call( cmd )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull down the filtered structures for looking at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this when working on local machine \n",
    "\n",
    "pull_list = [ 'dnh-aro/enzdes/try_1_out/{}.pdb'.format( i ) for i in filtered.description ]\n",
    "with open( 'results/pull_list', 'w' ) as fn:\n",
    "    fn.write( '\\n'.join( pull_list ) )\n",
    "\n",
    "#! head pull_list   \n",
    "! rsync -avz --files-from=results/pull_list $ep:. results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Manual curation of structures \n",
    "\n",
    "Now that we have run Rosetta simulations and picked a set of design critera to fiter by, it's time for manual curation of the structures. We'll download the 50 or so that look the best, and pick some designs to order. \n",
    "\n",
    "One thing that I really like to see when looking at a design is the mutations that were made when compared to the wild type enzyme. Let's diff the designs against their wild types (only those in the filtered list though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, let's try to automate the curation step. Let's write a function that\n",
    "\n",
    "+ takes a design PDB file name in enzdes/out\n",
    "\n",
    "and makes a nice PyMOL session with \n",
    "\n",
    "+ the wild type loaded and overlayed \n",
    "+ mutations colored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import string \n",
    "from shutil import copyfile\n",
    "\n",
    "designs = pandas.read_csv( 'results/filtered.csv', index_col='match' ) \n",
    "\n",
    "for name, s in designs.iterrows():\n",
    "    \n",
    "    # create sandbox \n",
    "    sandbox_path = 'results/{}_sandbox/'.format( name )\n",
    "    if not os.path.exists( sandbox_path ):\n",
    "        os.makedirs( sandbox_path )\n",
    "    \n",
    "    # construct paths \n",
    "    design_path = 'results/dnh-aro/enzdes/try_1_out/{}.pdb'.format( s.description ) \n",
    "    wt_path = 'match/scaffold_set/{}_11.pdb'.format( s.scaffold )\n",
    "    if os.path.exists( design_path ) and os.path.exists( wt_path ):\n",
    "        \n",
    "        # copy in files\n",
    "        my_des = design_path.split( '/' )[-1]\n",
    "        my_wt = '{}.pdb'.format( s.scaffold ) \n",
    "        \n",
    "        copyfile( 'match/scaffold_set/{}_11.pdb'.format( s.scaffold ), sandbox_path + my_wt )\n",
    "        copyfile( design_path, sandbox_path + my_des )\n",
    "        copyfile( 'match/LG1.conf.pdb', sandbox_path + 'LG1.conf.pdb' )\n",
    "        copyfile( 'match/LG1.params', sandbox_path + 'LG1.params' )\n",
    "        copyfile( 'match/hydratase.enzdes.cst', sandbox_path + 'hydratase.enzdes.cst' )\n",
    "        \n",
    "        # get mutations \n",
    "        with open( sandbox_path + my_des ) as design:\n",
    "            des_CA_lines = [ ln for ln in design.readlines() if 'ATOM' in ln and 'CA' in ln ]\n",
    "            des_CA = [ ln.split()[3] for ln in des_CA_lines ]\n",
    "            last_res = des_CA_lines[-1].split()[5]\n",
    "            \n",
    "        with open( sandbox_path + my_wt ) as wt:\n",
    "            wt_CA = [ ln.split()[3] for ln in wt.readlines() if 'ATOM' in ln and 'CA' in ln ]\n",
    "        \n",
    "        d3 = [ '%s%s%s' % ( a1, i, a2 ) for i, ( a1, a2 ) in enumerate( zip( wt_CA, des_CA ) ) if a1 != a2 ]\n",
    "        str_d3 = '+'.join( d3 ) \n",
    "        \n",
    "        with open( '{}/{}.pml'.format( sandbox_path, name ), 'w' ) as fn:\n",
    "            f = 'load {0}, {0}; load {1}, {1}; '.format( my_wt, my_des ) \n",
    "            resi = str_d3.translate( None, string.letters ) \n",
    "            g = 'sele muts, resi {} and obj {}; '.format( resi, my_des )  \n",
    "            h = 'util.cbaw muts; util.cnc; orient muts; show sticks, organic; hide (hydro); remove solvent;'\n",
    "            fn.write( f + g + h )\n",
    "        \n",
    "        with open( '{}/{}.puzzle_setup'.format( sandbox_path, name ), 'w' ) as fn:\n",
    "            p1 = 'version: 1\\n{{\\n\"sidechain_locked\": \"{0}||\"\\n\"backbone_locked\": \"{0}||\"\\n'.format( int( last_res ) + 1 ) \n",
    "            p2 = '\"can_design\": \"1-{}||\"\\n}}\\n'.format( last_res ) \n",
    "            fn.write( p1 + p2 )\n",
    "            #'version: 1\\n{\\n\"sidechain_locked\": \"%d||\"\\n\"backbone_locked\": \"%d||\"\\n\"can_design\": \"1-%d||\"\\n}\\n' % ( int( last_res ) + 1, int( last_res ) + 1, last_res )\n",
    "            \n",
    "        with open( '{}/notes.txt'.format( sandbox_path ), 'w' ) as fn:\n",
    "            lines = [ name, 'mutations: {}'.format( str_d3 ) ]\n",
    "            for col, item in s.iteritems():\n",
    "                lines.append( '{}: {}'.format( col, item ) )\n",
    "            fn.writelines( [ ln + '\\n' for ln in lines ] ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
